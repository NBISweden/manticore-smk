manticore-smk workflow results
==============================

manticore-smk_ is a Snakemake workflow for non model organism variant
calling and population genomics analyses. This analysis is based on
commit version {{ snakemake.config["__workflow_commit__"] }}_.

The analysis can be rerun with the following command:

.. code-block:: shell

   cd {{ snakemake.config["__workflow_workdir__"] }}
{% if snakemake.config["__workflow_basedir__"] == snakemake.config["__workflow_workdir__"] %}
   snakemake -j 1 --use-conda
{% else %}
   snakemake -j 1 --use-conda -s {{ snakemake.config["__workflow_basedir__"] }}/Snakefile
{% endif %}

.. note::

   Since the workflow is still work in progress, make sure to first
   run the commands with the `--dry-run` (`-n`) flag to make sure you
   don't inadvertedly have to regenerate large parts of the results.
   Many workflow dependencies are complex and in particular when
   running smaller parts of the workflow, unexpected things may
   happen.


Workflow summary
-----------------


The workflow runs the following steps:

1. read trimming (optional)
2. read mapping
3. raw variant calling
4. variant filtering
5. calculation of population genomics statistics
6. multiple qc checks


Data organization
=================

.. code-block:: text

   {{ snakemake.config["__workflow_workdir__"] }}/                    <- top-level project folder
   |
   ├── config                   <- configuration directory for Snakemake and other things
   │
   ├── data
   │   ├── external             <- data from third party sources
   │   ├── interim              <- Intermediate data that can be safely deleted
   │   ├── metadata             <- metadata describing raw data files
   │   ├── processed            <- Final processed data used for analyses
   │   └── raw                  <- The original immutable data dump to be treated as read-only.
   │
   ├── logs                     <- Collection of log outputs, e.g. from cluster managers
   │
   ├── reports                  <- Generated analyses and articles as html, pdf and more.
   |   ├── qc                   <- QC reports, including multiqc.html
   │   └── figures              <- Graphics for use in reports.
   │
   └── results                  <- Final results for sharing with collaborators, typically derived from analysis sets
       └── qc                   <- QC results


.. raw:: html

   <hr></hr>


Analysis overview
=================

The analyses can basically be divided in two parts: `Raw data
analysis`_ and `Analysis sets`_.

Raw data analysis
------------------

.. figure:: {{ snakemake.config["__workflow_basedir__"] }}/report/raw.svg
   :width: 40%
   :align: center

   Schematic overview of raw variant calling.

The raw data analysis generates raw unfiltered results that serve as a
starting point for subsequent analyses. Individual raw variant calls
are placed in ``results/ind/rawvc/{variantcaller}``, and pool raw
variant calls in ``results/pool/raw``.



Analysis sets
--------------

Once raw data has been generated it can be further analyzed in
*analysis sets*. Each analysis set has a configuration section named
``analysis/[0-9a-zA-Z-_]+`` with results for any given set ending up in
``results/ind`` or ``results/pool``.

An analysis set consists of *filters* that filter raw data and
*statistics* that generate statistics or plots of filtered data. The
entire analysis set can be configured to focus on prespecified
samples, regions, sex or populations.


Analysis set configuration
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Analysis sets have to be defined by the user. An example of a best
practice filtering analysis is shown below:


.. code-block:: yaml

   analysis/gatk_best_practice_snp:
     description: >-
       GATK best practice analysis for snps. Hard filters are applied
       to get a high-quality call set.
     group: ind
     tool: gatk
     filters:
       - select:
           options: --select-type-to-include SNP
       - filter:
           filters: ["QD < 2.0", "MQ < 40.0", "FS > 60.0", "MQRankSum < -12.5", "ReadPosRankSum < -8.0", "SOR > 3.0"]
       - concat:
           tool: bcftools

The analysis section is named ``analysis/gatk_best_practice_snp`` and
the results will in this case end up in
``results/ind/analysis/gatk_best_practice_snp``. The ``group`` config
key determines whether to run on individual (*ind*) or pool (*pool*)
data, where the input data is generated by the raw variant calling
step.

The tool defines what tool to run (currently *gatk* or
*bcftools*) for the subsequent steps. Then, in ``filters`` three
operations are applied to the input data: *select* (here with GATK
``SelectVariants``), *filter* (GATK ``VariantFilter``) and *concat*
(with ``bcftools concat``; note that setting ``tool`` changes from
GATK to bcftools in this context).



General analyses
=================

The analyses in this section apply to both individuals and pools.

QC
--

{% if "qc" in snakemake.config["workflow"].keys() %}

Numerous QC analyses have been performed:

{% for q in snakemake.config["workflow"]["qc"] %}

* {{ q }}

{% endfor %}


The results are stored in ``results/qc`` and summarized in
multiqc.html_.

All QC results can be regenerated by running

.. code-block:: shell

   snakemake all_qc

{% else %}

No QC has been performed.

{% endif %}

Trimming
--------

{% if snakemake.config["workflow"]["trim"] %}

Trimming has been performed with cutadapt. All read trimming can be
run as

.. code-block:: shell

   snakemake all_qc


Trimmed reads are output to ``data/interim/map/trim``.

{% else %}

Trimming has not been performed.

{% endif %}


Read mapping
------------

bwa was used to map reads to the reference ``{{ snakemake.config["db"]["ref"] }}``.

All reads can be mapped as

.. code-block:: shell

   snakemake all_map


Mapped reads are output to ``data/interim/map/{mapper}``. In addition,
individuals reads are deduplicated and output is placed in
``data/interim/map/{mapper}/dedup``.


Analysis of individual samples
==============================


Raw variant calling (``rawvc``)
--------------------------------

Raw variant result files are found in ``results/ind/rawvc/{caller}``.
Specifices of each caller are detailed below.


gatkhc
~~~~~~

All GATK calls can be generated as:

.. code-block:: shell

   snakemake all_rawvc

GATK HaplotypeCaller is first run in chunks on mapped reads, where
number of chunks can be set via configuration value
``config["workflow"]["regions"]["{name}"]["npart"]``. Every chunk
produces a temporary output gvcf file located in
``data/interim/ind/rawvc/gatkhc``. This is followed by
GenomicsDBImport where HaplotypeCaller chunk output is imported to
separate genomics databases at
``results/ind/rawvc/gatkhc/genomicsdb``. Finally, GenotypeGVCFs is run
in parallel on each database and the resulting vcfs are merged to
produce the final raw output at ``results/ind/rawvcf/gatkhc``. Chunk
files are indexed with a digit preceding the vcf suffix (e.g. 1.vcf.gz
for chunk 1).

.. note::

   Currently the raw output vcf contains all sites, both segregating
   and monomorphic. The information carried in monomorphic sites is
   essential for proper filtering. However, for large genomes and
   large numbers of samples, this may be inpractical. A WIP
   alternative is to store coverage information in separate files and
   use this information to filter sites.

{% if 'bcftools' in snakemake.config["workflow"]["variantcallers"]["ind"] %}

bcftools
~~~~~~~~

{% endif %}

{% if 'freebayes' in snakemake.config["workflow"]["variantcallers"]["ind"] %}

freebayes
~~~~~~~~~

{% endif %}


Analysis sets, individuals
---------------------------

Currently analysis sets have to be configured by the user. See
`Analysis sets`_ for an example of a best practice snp analysis and
`how to filter variants either with VQSR or by hard filtering
<https://gatk.broadinstitute.org/hc/en-us/articles/360035531112--How-to-Filter-variants-either-with-VQSR-or-by-hard-filtering#2>`_
for a discussion on the choice of filtering parameters.

.. note::

   There is currently no pseudotarget to rerun an analysis set. A
   workaround is to use one of the output files from the results as
   target for snakemake (e.g. `snakemake
   results/ind/analysis/{name}/{filter}/output.vcf`)


Analysis of pooled samples
==========================

Raw analysis
------------

Currently variant calling and analyses of pools is done with
popoolation_ and popoolation2_.

popoolation
~~~~~~~~~~~

The raw analysis simply consists of running samtools mpileup in
parallel on input bam files. The output consists of chunked
population-wise pileup files located at
``results/pool/raw/popoolation``.

popoolation2
~~~~~~~~~~~~

The raw analysis runs samtools mpileup on all samples in parallel and
the output is merged with popoolation2 mpileup2sync. The final output
consists of popoolation2 sync files grouped by sex and are located at
``results/pool/raw/popoolation2``. In addition, indels are separately
processed and output to ``results/pool/raw/popoolation2.indels``. The
indels can be used as input to downstream masking of popoolation
output.

Analysis sets, pools
--------------------

Currently analysis sets have to be configured by the user. Below are
examples of best practice like procedures for popoolation_ and
popoolation2_. Results are output to ``results/pool/analysis/{name}``.

.. code:: yaml

   analysis/popoolation_best_practice:
     description: >-
       Popoolation best practice analysis of individual pools.
     group: pool
     tool: popoolation
     filters:
       - mask:
           description: Remove indels
       - filter:
           options: --method withoutreplace --fastq-type sanger --target-coverage 2 --max-coverage 10 --min-qual 20
     statistics:
       - windowed_statistic:
           statistic: ["pi", "theta"]
           window_size: [10000]
           options: --min-count 2 --min-coverage 6 --min-covered-fraction .1 --fastq-type sanger


   analysis/popoolation2_best_practice:
     description: >-
       Popoolation2 best practice analysis of combined pools.
     group: pool
     tool: popoolation2
     filters:
       - mask:
           description: Remove indels
       - select:
           description: Select true indel sites with a perl snippet
       - filter:
           options: --max-coverage 8 --target-coverage 1 --method withoutreplace
     statistics:
       - windowed_statistic:
           statistic: ["fst", "fet"]
           window_size: [10000]
           options: --max-coverage 5
       - plain_statistic:
           statistic: ["rc", "pwc"]
           options: --max-coverage 5

Both procedures apply a masking step where indels are removed (using
the output in ``results/pool/raw/popoolation2.indel``), and in the
popoolation2 analysis, the `select` step selects indel sites based on
a perl regex. Filtering of sites is then performed for both
procedures, followed by calculation of various statistics.

Workflow graph
==============

.. _manticore-smk: https://github.com/NBISweden/manticore-smk
.. _multiqc.html: ./qc/multiqc.html
.. _{{ snakemake.config["__workflow_commit__"] }}: {{ snakemake.config["__workflow_commit_link__"] }}
.. _gatk_hard_filter:
.. _popoolation: https://sourceforge.net/projects/popoolation/
.. _popoolation2: https://sourceforge.net/projects/popoolation2/
